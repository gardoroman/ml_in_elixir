# ML in Elixir Chapter 1

```elixir
Mix.install([
  {:axon, "~> 0.5"},
  {:nx, "~> 0.5"},
  {:explorer, "~> 0.5"},
  {:kino, "~> 0.8"}
])
```

## Section

```elixir
require Explorer.DataFrame, as: DF

iris = Explorer.Datasets.iris()
```

```elixir
DF.shape(iris)
```

```elixir
cols = ~w(sepal_width sepal_length petal_length petal_width)
```

note: `across` is a macro in Explorer. The `^` below is required to access variables outside of the query.

```elixir
normalized_iris =
  DF.mutate(
    iris,
    for col <- across(^cols) do
      {col.name, (col - mean(col)) / variance(col)}
    end
  )
```

Shuffle the data below to simulate a production environment

```elixir
normalized_iris =
  DF.mutate(normalized_iris,
    species: Explorer.Series.cast(species, :category)
  )

shuffled_normalized_iris = DF.shuffle(normalized_iris)
```

Slice the data to create a _holdout_ dataset.

```elixir
train_df = DF.slice(shuffled_normalized_iris, 0..119)
test_df = DF.slice(shuffled_normalized_iris, 120..149)
```

### one-hot encoding

```elixir
feature_columns = [
  "sepal_length",
  "sepal_width",
  "petal_length",
  "petal_width"
]
```

```elixir
x_train = Nx.stack(train_df[feature_columns], axis: -1)
```

```elixir
y_train =
  train_df["species"]
  |> Nx.stack(axis: -1)
  |> Nx.equal(Nx.iota({1, 3}, axis: -1))
```

```elixir
x_test = Nx.stack(test_df[feature_columns], axis: -1)
```

```elixir
y_test =
  test_df["species"]
  |> Nx.stack(axis: -1)
  |> Nx.equal(Nx.iota({1, 3}, axis: -1))
```

`Nx.stack/2` converts features in a DataFrame into a tensor. This will stack the rows of a DataFrame into individual entries.  
A labels tensor is extracted by one-hot encoding the species column. This is done by converting the _species_ column to a tensor, which implicitly casts each category to a unique integer.

<!-- livebook:{"break_markdown":true} -->

`Axon.dense` determines the amount of layers. Dense means that the parent layer sents weights to the child layers.

```elixir
model =
  Axon.input("iris_features", shape: {nil, 4})
  |> Axon.dense(3, activation: :softmax)
```

```elixir
Axon.Display.as_graph(model, Nx.template({1, 4}, :f32))
```

```elixir
data_stream =
  Stream.repeatedly(fn ->
    {x_train, y_train}
  end)
```

`sgd` stands for stochastic gradient descent

```elixir
trained_model_state =
  model
  |> Axon.Loop.trainer(:categorical_cross_entropy, :sgd)
  |> Axon.Loop.metric(:accuracy)
  |> Axon.Loop.run(data_stream, %{}, iterations: 500, epochs: 10)
```

```elixir
data = [{x_test, y_test}]

model
|> Axon.Loop.evaluator()
|> Axon.Loop.metric(:accuracy)
|> Axon.Loop.run(data, trained_model_state)
```
