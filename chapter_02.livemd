# ML in Elixir Chapter 2

```elixir
Mix.install([
  {:nx, "~> 0.5"},
  {:exla, "~> 0.5"},
  {:benchee, github: "bencheeorg/benchee", override: true}
])
```

## Thinking In Tensors

```elixir
Nx.tensor([1, 2, 3])
```

```elixir
a = Nx.tensor([[1, 2, 3], [4, 5, 6]])
```

```elixir
b = Nx.tensor(1.0)
```

```elixir
Nx.tensor([[[[[[1.0, 2]]]]]])
```

### Tensors Have a Type

```elixir
a = Nx.tensor([1, 2])
```

```elixir
b = Nx.tensor([1.0, 2.0])
```

The second paramater to `Nx.tensor/2` takes a keyword list of options, one of them being the type.  
It can be specified as a tuple, eg:

```
signed:   {:s, [8, 16, 32, 64]}
unsigned: {:u, [8, 16, 32, 64]}
float:    {:f [16, 32, 64]}
brain     {:bf, 16}
complex   {::c, 64, 128}
```

```elixir
Nx.tensor(128, type: {:s, 8})
```

```elixir
Nx.tensor(128, type: {:s, 16})
```

```elixir
Nx.tensor(128)
```

### Tensors Have a Shape

```elixir
Nx.tensor([1, 2])
```

```elixir
Nx.tensor([[1, 2], [3, 4]])
```

```elixir
Nx.tensor([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])
```

```elixir
Nx.tensor([[1, 2, 3], [4, 5, 6]], names: [:x, :y])
```

## Using Nx Operations

### Shape and Type Operations

```elixir
a = Nx.tensor([1, 2, 3])
```

```elixir
a
|> Nx.as_type({:f, 32})
|> Nx.reshape({1, 3, 1})
```

```elixir
Nx.reshape(a, {1, 1, 3})
```

```elixir
Nx.reshape(a, {3, 1, 1})
```

### Element-Wise Unary Operations

```elixir
a = [-1, -2, -3, 0, 1, 2, 3] |> Enum.map(&abs/1)
```

```elixir
a = Nx.tensor([[[-1, -2, 3], [-4, -5, -6]], [[1, 2, 3], [4, 5, 6]]])
```

```elixir
Nx.abs(a)
```

### Element-wise Binary Operations

```elixir
a = [1, 2, 3]
b = [4, 5, 6]
Enum.zip_with(a, b, &(&1 + &2))
```

```elixir
a = Nx.tensor([[1, 2, 3], [4, 5, 6]])
b = Nx.tensor([[7, 8, 9], [10, 11, 12]])
Nx.add(a, b)
```

```elixir
Nx.shape(a)
```

```elixir
Nx.tensor(5) |> Nx.shape()
```

_Broadcasting Examples_

```elixir
Nx.add(5, Nx.tensor([1, 2, 3]))
```

```elixir
Nx.add(Nx.tensor(5), Nx.tensor([1, 2, 3]))
```

```elixir
Nx.add(Nx.tensor([1, 2, 3]), Nx.tensor([[4, 5, 6], [7, 8, 9]]))
```

```elixir
Nx.add(Nx.tensor([1, 2, 3]), Nx.tensor([[4, 5, 6], [7]]))
```

### Reductions

```elixir
revs = Nx.tensor([85, 76, 42, 34, 46, 23, 52, 99, 22, 32, 85, 51])
```

```elixir
Nx.sum(revs)
```

```elixir
y1 = Enum.map(0..11, fn _ -> Enum.random(21..99) end)
y2 = Enum.map(0..11, fn _ -> Enum.random(21..99) end)
y3 = Enum.map(0..11, fn _ -> Enum.random(21..99) end)
y4 = Enum.map(0..11, fn _ -> Enum.random(21..99) end)

revs = Nx.tensor([y1, y2, y3, y4], names: [:year, :month])
```

```elixir
Nx.sum(revs, axes: [:year])
```

```elixir
Nx.sum(revs, axes: [:month])
```

```elixir
defmodule Softmax do
  import Nx.Defn

  defn softmax(n) do
    Nx.exp(n) / Nx.sum(Nx.exp(n))
  end
end
```

```elixir
key = Nx.Random.key(42)
```

```elixir
{tensor, _key} = Nx.Random.uniform(key, shape: {1_000_000})

Benchee.run(
  %{
    "JIT with EXLA" => fn ->
      apply(EXLA.jit(&Softmax.softmax/1), [tensor])
    end,
    "Regular Elixir" => fn ->
      Softmax.softmax(tensor)
    end
  },
  time: 10
)
```

Additional examples form Dockyard article [Up and Running Nx]](https://dockyard.com/blog/2021/04/08/up-and-running-nx)

```elixir
Nx.mean(Nx.tensor([[1, 2, 3], [4, 5, 6]]), axes: [1])
```

```elixir
t1 = Nx.tensor([[1, 2, 3], [4, 5, 6]])
```

```elixir
Nx.mean(t1, axes: [0])
```

```elixir
Nx.mean(t1, axes: [1, 0])
```

```elixir
Nx.mean(t1, axes: [0, 1])
```

```elixir
t2 = Nx.tensor([[[1, 2, 3], [4, 5, 6]]])
```

```elixir
Nx.mean(t2, axes: [1, 0])
```

```elixir
Nx.mean(t2, axes: [0, 1])
```

```elixir
Nx.mean(t2, axes: [0])
```

```elixir
Nx.mean(t2, axes: [1])
```

```elixir
Nx.iota({2, 2, 3})
```
